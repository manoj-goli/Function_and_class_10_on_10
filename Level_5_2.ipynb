{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec52db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoints.txt (one per line)\n",
    "# api1.example.com\n",
    "# api2.example.com\n",
    "# api3.example.com\n",
    "# api4.example.com\n",
    "# api5.example.com\n",
    "# api6.example.com\n",
    "# api7.example.com\n",
    "# api8.example.com\n",
    "# api9.example.com\n",
    "# api10.example.com\n",
    "\n",
    "# Assume these are the p95_ms values returned by each host's /metrics JSON:\n",
    "# api1: 120, api2: 180, api3: timeout, api4: 150, api5: 90,\n",
    "# api6: 210, api7: 200, api8: 160, api9: 140, api10: 170\n",
    "#\n",
    "# Rule for this exercise:\n",
    "# - timeouts count as missing data (skip them, but report how many timeouts)\n",
    "# - ALERT if avg_p95_ms >= threshold_ms\n",
    "#\n",
    "# With threshold_ms=160:\n",
    "# avg of [120,180,150,90,210,200,160,140,170] = 1420/9 = 157.78 => OK\n",
    "# Output:\n",
    "# OK: avg_p95_ms=157.8 threshold_ms=160 samples=9 timeouts=1\n",
    "#\n",
    "# With threshold_ms=150:\n",
    "# ALERT (157.8 >= 150)\n",
    "# ALERT: avg_p95_ms=157.8 threshold_ms=150 samples=9 timeouts=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c4b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "def fetch_metrics(host, timeout=\"2\"):\n",
    "    # Uses curl to simplify (pretend curl is available)\n",
    "    url = \"https://\" + host + \"/metrics\"\n",
    "    out = subprocess.check_output([\"curl\", \"-sS\", \"--max-time\", timeout, url], text=True)\n",
    "    return json.loads(out)\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) != 2:\n",
    "        raise ValueError(\"usage: p95mon.py <endpoints_file> <threshold_ms>\")\n",
    "\n",
    "    path = argv[0]\n",
    "    threshold = argv[1]\n",
    "\n",
    "    values = []\n",
    "    timeouts = 0\n",
    "\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            host = line.strip()\n",
    "            if not host or host.startswith(\"#\"):\n",
    "                continue\n",
    "            try:\n",
    "                data = fetch_metrics(host)\n",
    "                p95 = data.get(\"p95_ms\", \"0\")\n",
    "                values.append(p95)\n",
    "            except subprocess.CalledProcessError:\n",
    "                timeouts += 1\n",
    "\n",
    "    avg = sum(values) / len(values)\n",
    "\n",
    "    if avg >= threshold:\n",
    "        print(f\"ALERT: avg_p95_ms={avg:.1f} threshold_ms={threshold} samples={len(values)} timeouts={timeouts}\")\n",
    "    else:\n",
    "        print(f\"OK: avg_p95_ms={avg:.1f} threshold_ms={threshold} samples={len(values)} timeouts={timeouts}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e9a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # endpoints.txt (one per line)\n",
    "# api1.example.com\n",
    "# api2.example.com\n",
    "# api3.example.com\n",
    "# api4.example.com\n",
    "# api5.example.com\n",
    "# api6.example.com\n",
    "# api7.example.com\n",
    "# api8.example.com\n",
    "# api9.example.com\n",
    "# api10.example.com\n",
    "\n",
    "# Assume these are the p95_ms values returned by each host's /metrics JSON:\n",
    "# api1: 120, api2: 180, api3: timeout, api4: 150, api5: 90,\n",
    "# api6: 210, api7: 200, api8: 160, api9: 140, api10: 170\n",
    "#\n",
    "# Rule for this exercise:\n",
    "# - timeouts count as missing data (skip them, but report how many timeouts)\n",
    "# - ALERT if avg_p95_ms >= threshold_ms\n",
    "#\n",
    "# With threshold_ms=160:\n",
    "# avg of [120,180,150,90,210,200,160,140,170] = 1420/9 = 157.78 => OK\n",
    "# Output:\n",
    "# OK: avg_p95_ms=157.8 threshold_ms=160 samples=9 timeouts=1\n",
    "#\n",
    "# With threshold_ms=150:\n",
    "# ALERT (157.8 >= 150)\n",
    "# ALERT: avg_p95_ms=157.8 threshold_ms=150 samples=9 timeouts=1\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import subprocess\n",
    "\n",
    "def fetch_metrics(host, timeout=\"2\"): #this takes the host and default value of timeout in \"str\"\"\n",
    "    # Uses curl to simplify (pretend curl is available)\n",
    "    url = \"https://\" + host + \"/metrics\" #string concatination\n",
    "    \n",
    "    \n",
    "    out = subprocess.check_output([\"curl\", \"-sS\", \"--max-time\", timeout, url], text=True) #text=True gives us python string output, \n",
    "    #1iter: url=\"https://api1.example.com/metrics\"\n",
    "    \n",
    "    #for handling exception from timeouts, it is handled in the main fn\n",
    "    \n",
    "    \n",
    "    return json.loads(out) #returns a output with is a dict\n",
    "\n",
    "def main(argv):\n",
    "    if len(argv) != 2: #we are assuming 2 args of length, if not raise error\n",
    "        raise ValueError(\"usage: p95mon.py <endpoints_file> <threshold_ms>\")\n",
    "\n",
    "    path = argv[0] #\"\"\n",
    "    threshold = float(argv[1]) # \"\"\n",
    "\n",
    "    values = [] #\n",
    "    timeouts = 0 #int\n",
    "\n",
    "    with open(path) as f: #it does not have permissions like r,r+,w\n",
    "    #(PP1* - write a try, except blocks to handle missing file with a FileNotFound exception)\n",
    "        for line in f: # api1.example.com\n",
    "            host = line.strip() #strips empty spaces before and after\n",
    "            if not host or host.startswith(\"#\"): #this handles/skips empty lines or lines with #\n",
    "                continue\n",
    "            try:\n",
    "                data = fetch_metrics(host) #calling helper function\n",
    "                # api1: 120, api2: 180, api3: timeout, api4: 150, api5: 90,\n",
    "                \n",
    "                \n",
    "                p95 = data.get(\"p95_ms\", 0) #we are trying to get the value in the key p95, and also given a default value of \"0\" STR, so I made 0 as int\n",
    "                \n",
    "                \n",
    "                values.append(p95) #value=[120,180,150,190....] #there wont be timeouts in the list because we are handling using except below\n",
    "            except subprocess.CalledProcessError:\n",
    "                timeouts += 1 #1 as per assumed input data\n",
    "\n",
    "    avg = sum(values) / len(values) #here the length could be zero if the list is empty. so do, if len(values) > 0: then do the avg operation\n",
    "\n",
    "    if avg >= threshold:\n",
    "        print(f\"ALERT: avg_p95_ms={avg:.1f} threshold_ms={threshold} samples={len(values)} timeouts={timeouts}\")\n",
    "        #ALERT: avg_p95_ms=(prints avg with 1 decimal) threshold_ms=(prints threshold given in command) samples=(prints number of values) timeouts=(final number of timeouts)\n",
    "    else:\n",
    "        print(f\"OK: avg_p95_ms={avg:.1f} threshold_ms={threshold} samples={len(values)} timeouts={timeouts}\")\n",
    "        #similarly like above ALERT comment\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:]) #slice first two args of command and take the rest\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745b014",
   "metadata": {},
   "source": [
    "You’re on the right track here — this one is *exactly* the kind of snippet where datatype discipline matters, and you fixed the most obvious one.\n",
    "\n",
    "## What you did well ✅\n",
    "\n",
    "* ✅ Converted `threshold` to `float(argv[1])` (original would compare float to str and crash).\n",
    "* ✅ Changed default `p95_ms` to numeric `0` (better than `\"0\"`).\n",
    "* ✅ Noted the divide-by-zero risk when `values` is empty.\n",
    "\n",
    "## What you missed (what the interviewer expects)\n",
    "\n",
    "### 1) Major bug (types inside `values`)\n",
    "\n",
    "Even after your changes, `p95` might still be a **string** coming from JSON (common: `\"p95_ms\": \"120\"`). Then:\n",
    "\n",
    "```python\n",
    "avg = sum(values) / len(values)\n",
    "```\n",
    "\n",
    "will crash if `values` contains strings, or produce nonsense if mixed.\n",
    "\n",
    "**Fix:** force numeric:\n",
    "\n",
    "```python\n",
    "p95 = float(data.get(\"p95_ms\"))\n",
    "values.append(p95)\n",
    "```\n",
    "\n",
    "and handle missing/null with guard.\n",
    "\n",
    "### 2) Logic error (timeouts classification)\n",
    "\n",
    "The code assumes:\n",
    "\n",
    "```python\n",
    "except subprocess.CalledProcessError:\n",
    "    timeouts += 1\n",
    "```\n",
    "\n",
    "But `curl --max-time` timeout usually returns exit code **28**, but `CalledProcessError` also happens for many other things (DNS failure, SSL, connection refused depending on flags). So counting *all* CalledProcessError as “timeouts” is a logic error.\n",
    "\n",
    "**Fix:** check the return code or stderr text and classify properly:\n",
    "\n",
    "* if returncode == 28 → timeout\n",
    "* else → failure (could count separately or treat as skip, depending on requirement)\n",
    "\n",
    "### 3) Edge case where it breaks\n",
    "\n",
    "You already identified one: **all endpoints fail/timeout** → `len(values)==0` → division by zero.\n",
    "\n",
    "Another common edge case: invalid JSON (HTML error page, proxy block page) → `json.loads(out)` raises `JSONDecodeError` (not caught).\n",
    "\n",
    "## One more small thing\n",
    "\n",
    "In your final comment:\n",
    "\n",
    "```python\n",
    "main(sys.argv[1:])  # slice first two args\n",
    "```\n",
    "\n",
    "That comment is slightly off: `sys.argv[1:]` removes only the program name, not “first two args.” (Minor, but avoid confusing yourself.)\n",
    "\n",
    "---\n",
    "\n",
    "## Rating: **7/10**\n",
    "\n",
    "You fixed the `threshold` type issue and spotted empty-list risk. To hit 8–9, you need to consistently:\n",
    "\n",
    "* cast JSON numbers to float/int,\n",
    "* distinguish timeout vs other curl failures,\n",
    "* handle invalid JSON.\n",
    "\n",
    "---\n",
    "\n",
    "## What a clean “TSE answer” would look like (high-level patch)\n",
    "\n",
    "* Convert threshold to float ✅\n",
    "* Convert p95 to float (and skip if missing)\n",
    "* Handle:\n",
    "\n",
    "  * `CalledProcessError` returncode 28 as timeout, others as `failures`\n",
    "  * `JSONDecodeError`\n",
    "* Guard zero samples\n",
    "\n",
    "Example minimal change set:\n",
    "\n",
    "```python\n",
    "threshold = float(argv[1])\n",
    "\n",
    "...\n",
    "try:\n",
    "    data = fetch_metrics(host)\n",
    "    p95_raw = data.get(\"p95_ms\", None)\n",
    "    if p95_raw is None:\n",
    "        continue\n",
    "    values.append(float(p95_raw))\n",
    "except subprocess.CalledProcessError as e:\n",
    "    if e.returncode == 28:\n",
    "        timeouts += 1\n",
    "    else:\n",
    "        failures += 1\n",
    "except json.JSONDecodeError:\n",
    "    failures += 1\n",
    "\n",
    "if not values:\n",
    "    print(f\"ALERT: no_samples threshold_ms={threshold} timeouts={timeouts}\")\n",
    "    return\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "If you want the next one (same difficulty, still network/TSE), I’ll give a snippet where the bug is **HTTPError vs URLError ordering + mis-parsing status codes**, with ~12 inputs and a threshold calculation again.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
